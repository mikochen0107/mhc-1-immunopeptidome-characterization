{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impepdom Test Set Performance Analyses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")  # add top folder to path\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as sts\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "import impepdom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Should make this whole block as functions inside Impepdom package later\n",
    "'''\n",
    "def weighted_harmonic_mean(var_1, var_2, beta=1):  # should make it generalizable to many variables\n",
    "    '''\n",
    "    Harmonic mean for two parameters with weighting.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    var_1, var_2: int or ndarray\n",
    "        Variables to consider\n",
    "        \n",
    "    beta: float, optional\n",
    "        Importance of `var_2` relative to `var_1`.\n",
    "        If beta == 1, this function is equivalent to `scipy.stats.hmean()`\n",
    "    '''\n",
    "    \n",
    "    return (1 + beta**2) * np.multiply(var_1, var_2) / (beta**2 * var_1 + var_2)\n",
    "\n",
    "def get_best_hyperparams(file, padding='end'):\n",
    "    '''\n",
    "    Extract the best hyperparameters for a model with harmonic weighting\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file: string\n",
    "        Name of the CSV file contraining hyperparam results\n",
    "    '''\n",
    "\n",
    "    path = '../store/hyperparams'\n",
    "\n",
    "    file_end = file.find('.csv')\n",
    "    file_begin = max(file.find('mlp'), file.find('cnn'))\n",
    "    all_name = file[file_end-6:file_end-2] + (':' if file.find(':') == -1 else '') + file[file_end-2:file_end]\n",
    "    allele = 'HLA-' + all_name.upper() # change to appropriate name\n",
    "\n",
    "    df = pd.read_csv(path + '/' + file)\n",
    "    correct_padding = (df['padding'] == padding)\n",
    "    df = df[correct_padding].reset_index()\n",
    "    idx = (df['min_auc'].notna() & df['mean_ppv'].notna())\n",
    "    \n",
    "    metric_1, metric_2 = np.array(df['min_auc'][idx]), np.array(df['mean_ppv'][idx])\n",
    "    beta = 1  # how much the second metric should be weighted compared to the first\n",
    "    w_hmean = weighted_harmonic_mean(metric_1, metric_2, beta=0.6)\n",
    "    \n",
    "    best_3_rows = (-w_hmean).argsort()[:3] # for top 3 rows with best harmonic mean value\n",
    "    # best_3_rows = (-sts.hmean([df['min_auc'][idx], df['mean_ppv'][idx]])).argsort()[:3]\n",
    "    \n",
    "    batch_sizes = list(df['batch_size'][best_3_rows].astype('int'))\n",
    "    batch_counter = Counter(batch_sizes)\n",
    "    batch_sz = batch_counter.most_common(1)[0][0]\n",
    "    \n",
    "    hyperparams = {\n",
    "        'hla_allele': allele, \n",
    "        'padding': padding,\n",
    "        'batch_size': batch_sz, \n",
    "        'num_epochs': int(np.mean(df['num_epochs'][best_3_rows])),\n",
    "        'learning_rate': float(np.mean(df['learning_rate'][best_3_rows])),\n",
    "\n",
    "        'min_auc': list(metric_1[best_3_rows]),\n",
    "        'mean_ppv': list(metric_2[best_3_rows]),\n",
    "    }\n",
    "\n",
    "    if 'mean_pcc' in df.columns:\n",
    "        hyperparams['mean_pcc'] = list(df['mean_pcc'][best_3_rows])\n",
    "    if 'dropout_input' in df.columns and 'dropout_hidden' in df.columns:\n",
    "        hyperparams['dropout_input'] = float(np.mean(df['dropout_input'][best_3_rows]))\n",
    "        hyperparams['dropout_hidden'] = float(np.mean(df['dropout_hidden'][best_3_rows]))\n",
    "    else:\n",
    "        hyperparams['dropout_input'] = 0.65  # stolen from MLP end\n",
    "        hyperparams['dropout_hidden'] = 0.46\n",
    "        \n",
    "    hyperparams['conv'] = False\n",
    "    if 'conv' in df.columns:\n",
    "        if df['conv'][0] == 'True':\n",
    "            hyperparams['conv'] = True\n",
    "            \n",
    "    if 'num_conv_layers' in df.columns and 'conv_filt_sz' in df.columns\tand 'conv_stride' in df.columns:\n",
    "        hyperparams['num_conv_layers'] = int(np.max(df['num_conv_layers'][best_3_rows]))\n",
    "        hyperparams['conv_filt_sz'] = int(np.max(df['conv_filt_sz'][best_3_rows]))\n",
    "        hyperparams['conv_stride'] = int(np.max(df['conv_stride'][best_3_rows]))\n",
    "    else:\n",
    "        hyperparams['num_conv_layers'] = 1  # default params for conv\n",
    "        hyperparams['conv_filt_sz'] = 5\n",
    "        hyperparams['conv_stride'] = 2\n",
    "\n",
    "    return hyperparams\n",
    "\n",
    "def make_trained_model(hyperparams):\n",
    "    results = []\n",
    "\n",
    "    impepdom.time_tracker.reset_timer() \n",
    "\n",
    "    print('working with allele', hyperparams['hla_allele'])\n",
    "    dataset = impepdom.PeptideDataset(\n",
    "        hla_allele=hyperparams['hla_allele'],\n",
    "        padding=hyperparams['padding'],\n",
    "        toy=False)\n",
    "\n",
    "    save_folder, baseline_metrics, _ = impepdom.run_experiment(\n",
    "        model_type='MultilayerPerceptron',  # passing model type here\n",
    "        dataset=dataset,\n",
    "        train_fold_idx=[0, 1, 2, 3, 4],\n",
    "        learning_rate=hyperparams['learning_rate'],\n",
    "        num_epochs=hyperparams['num_epochs'],\n",
    "        batch_size=hyperparams['batch_size'],\n",
    "\n",
    "        show_output=True,\n",
    "        dropout_input=hyperparams['dropout_input'],\n",
    "        dropout_hidden=hyperparams['dropout_hidden'],\n",
    "\n",
    "        conv=hyperparams['conv'],\n",
    "        num_conv_layers=hyperparams['num_conv_layers'],\n",
    "        conv_filt_sz=hyperparams['conv_filt_sz'],\n",
    "        conv_stride=hyperparams['conv_stride']\n",
    "    )\n",
    "\n",
    "    model = impepdom.models['MultilayerPerceptron'](\n",
    "        dropout_input=hyperparams['dropout_input'],\n",
    "        dropout_hidden=hyperparams['dropout_hidden'],\n",
    "\n",
    "        conv=hyperparams['conv'],\n",
    "        num_conv_layers=hyperparams['num_conv_layers'],\n",
    "        conv_filt_sz=hyperparams['conv_filt_sz'],\n",
    "        conv_stride=hyperparams['conv_stride']\n",
    "    )\n",
    "    \n",
    "    # to load a trained model, you would need to initialize the model outside\n",
    "    # smth like (untrained) `model = impepdom.models.MultilayerPerceptron(num_hidden_layers=2, hidden_layer_size=100)`\n",
    "    # but specify params exactly the same as in hyperparam_search\n",
    "                                                                    # get from csv file (column \"model\")\n",
    "    trained_model, _ = impepdom.load_trained_model(model, save_folder)\n",
    "\n",
    "    return trained_model, save_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Impepdom MLP, Padding End (A01:01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hla_allele': 'HLA-A01:01',\n",
       " 'padding': 'end',\n",
       " 'batch_size': 32,\n",
       " 'num_epochs': 10,\n",
       " 'learning_rate': 0.001,\n",
       " 'min_auc': [0.8977589504924592, 0.8961656106026613, 0.8990260131998715],\n",
       " 'mean_ppv': [0.5537177398133175, 0.5552848410310801, 0.5488537884133244],\n",
       " 'mean_pcc': [0.6042904818034925, 0.6009710200191343, 0.6021092651503497],\n",
       " 'dropout_input': 0.65,\n",
       " 'dropout_hidden': 0.4666666666666666,\n",
       " 'conv': False,\n",
       " 'num_conv_layers': 2,\n",
       " 'conv_filt_sz': 5,\n",
       " 'conv_stride': 1}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyp_mlp_end = get_best_hyperparams('mlp_2x100_a01:01.csv', padding='end')\n",
    "hyp_mlp_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working with allele HLA-A01:01\n",
      "[1 m 12 s] peptide dataset initialized\n",
      "epoch 1/10 started at 0.0005 s\n",
      "train loss: 0.0366 acc: 0.9917 auc: 0.8827\n",
      "\n",
      "epoch 2/10 started at 76.0032 s\n",
      "train loss: 0.0339 acc: 0.9926 auc: 0.8911\n",
      "\n",
      "epoch 3/10 started at 149.1546 s\n",
      "train loss: 0.0329 acc: 0.9928 auc: 0.8922\n",
      "\n",
      "epoch 4/10 started at 221.5307 s\n",
      "train loss: 0.0313 acc: 0.9932 auc: 0.8967\n",
      "\n",
      "epoch 5/10 started at 294.6287 s\n",
      "train loss: 0.0321 acc: 0.9932 auc: 0.8904\n",
      "\n",
      "epoch 6/10 started at 368.3679 s\n",
      "train loss: 0.0313 acc: 0.9933 auc: 0.8961\n",
      "\n",
      "epoch 7/10 started at 443.1616 s\n",
      "train loss: 0.0325 acc: 0.9930 auc: 0.8905\n",
      "\n",
      "epoch 8/10 started at 518.5411 s\n",
      "train loss: 0.0312 acc: 0.9932 auc: 0.8932\n",
      "\n",
      "epoch 9/10 started at 594.3561 s\n",
      "train loss: 0.0314 acc: 0.9932 auc: 0.8917\n",
      "\n",
      "epoch 10/10 started at 670.5593 s\n",
      "train loss: 0.0317 acc: 0.9932 auc: 0.8860\n",
      "\n",
      "training completed in 12 m 35.4826 s\n",
      "best training auc: 0.8967\n"
     ]
    }
   ],
   "source": [
    "trained_mlp_end, save_folder_mlp_end = make_trained_model(hyp_mlp_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Impepdom MLP, Padding Flurry (A01:01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hla_allele': 'HLA-A01:01',\n",
       " 'padding': 'flurry',\n",
       " 'batch_size': 32,\n",
       " 'num_epochs': 2,\n",
       " 'learning_rate': 0.005,\n",
       " 'min_auc': [0.872914348179539, 0.8887562782268924, 0.8829656080326539],\n",
       " 'mean_ppv': [0.702036238962418, 0.6725481692381067, 0.6724674239309099],\n",
       " 'dropout_input': 0.65,\n",
       " 'dropout_hidden': 0.46,\n",
       " 'conv': False,\n",
       " 'num_conv_layers': 1,\n",
       " 'conv_filt_sz': 5,\n",
       " 'conv_stride': 2}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyp_mlp_flurry = get_best_hyperparams('flurry_mlp_2x100_a01:01.csv', padding='flurry')\n",
    "hyp_mlp_flurry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working with allele HLA-A01:01\n",
      "[1 m 18 s] peptide dataset initialized\n",
      "epoch 1/2 started at 0.0006 s\n",
      "train loss: 0.0367 acc: 0.9921 auc: 0.8990\n",
      "\n",
      "epoch 2/2 started at 80.6436 s\n",
      "train loss: 0.0360 acc: 0.9923 auc: 0.9101\n",
      "\n",
      "training completed in 2 m 38.5692 s\n",
      "best training auc: 0.9101\n"
     ]
    }
   ],
   "source": [
    "trained_mlp_flurry, save_folder_mlp_flurry = make_trained_model(hyp_mlp_flurry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Impepdom CNN, Padding Flurry (A01:01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hla_allele': 'HLA-A01:01',\n",
       " 'padding': 'flurry',\n",
       " 'batch_size': 32,\n",
       " 'num_epochs': 6,\n",
       " 'learning_rate': 0.0007,\n",
       " 'min_auc': [0.9343186974226512, 0.930497976816677, 0.935205387103132],\n",
       " 'mean_ppv': [0.5999044863447609, 0.6009233348300029, 0.5940511290114937],\n",
       " 'mean_pcc': [0.6569269182965304, 0.6589301105293429, 0.6550037584822265],\n",
       " 'dropout_input': 0.16666666666666666,\n",
       " 'dropout_hidden': 0.4166666666666667,\n",
       " 'conv': True,\n",
       " 'num_conv_layers': 2,\n",
       " 'conv_filt_sz': 5,\n",
       " 'conv_stride': 1}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyp_cnn_flurry = get_best_hyperparams('mlp_2x100_cnn_a01:01.csv', padding='flurry')\n",
    "hyp_cnn_flurry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working with allele HLA-A01:01\n",
      "[1 m 16 s] peptide dataset initialized\n",
      "epoch 1/6 started at 0.0008 s\n",
      "train loss: 0.0303 acc: 0.9930 auc: 0.9142\n",
      "\n",
      "epoch 2/6 started at 295.2853 s\n",
      "train loss: 0.0265 acc: 0.9937 auc: 0.9341\n",
      "\n",
      "epoch 3/6 started at 600.7621 s\n",
      "train loss: 0.0257 acc: 0.9938 auc: 0.9426\n",
      "\n",
      "epoch 4/6 started at 995.9847 s\n",
      "train loss: 0.0248 acc: 0.9941 auc: 0.9441\n",
      "\n",
      "epoch 5/6 started at 1340.9808 s\n",
      "train loss: 0.0250 acc: 0.9939 auc: 0.9463\n",
      "\n",
      "epoch 6/6 started at 1683.5154 s\n",
      "train loss: 0.0241 acc: 0.9942 auc: 0.9516\n",
      "\n",
      "training completed in 33 m 45.9678 s\n",
      "best training auc: 0.9516\n"
     ]
    }
   ],
   "source": [
    "trained_cnn_flurry, save_folder_cnn_flurry = make_trained_model(hyp_cnn_flurry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Impepdom CNN, Padding End (A01:01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hla_allele': 'HLA-A01:01',\n",
       " 'padding': 'end',\n",
       " 'batch_size': 32,\n",
       " 'num_epochs': 4,\n",
       " 'learning_rate': 0.0007,\n",
       " 'min_auc': [0.9368633953874179, 0.9313492851709656, 0.9336545279088934],\n",
       " 'mean_ppv': [0.5958793626912142, 0.597742716862056, 0.5931293774163101],\n",
       " 'mean_pcc': [0.6562752247286305, 0.6550852579461708, 0.6530620180032013],\n",
       " 'dropout_input': 0.18333333333333335,\n",
       " 'dropout_hidden': 0.45,\n",
       " 'conv': True,\n",
       " 'num_conv_layers': 2,\n",
       " 'conv_filt_sz': 5,\n",
       " 'conv_stride': 1}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyp_cnn_end = get_best_hyperparams('mlp_2x100_cnn_a01:01.csv', padding='end')\n",
    "hyp_cnn_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working with allele HLA-A01:01\n",
      "[1 m 15 s] peptide dataset initialized\n",
      "epoch 1/4 started at 0.0006 s\n",
      "train loss: 0.0317 acc: 0.9929 auc: 0.9056\n",
      "\n",
      "epoch 2/4 started at 308.7786 s\n",
      "train loss: 0.0260 acc: 0.9939 auc: 0.9386\n",
      "\n",
      "epoch 3/4 started at 627.1995 s\n",
      "train loss: 0.0254 acc: 0.9938 auc: 0.9438\n",
      "\n",
      "epoch 4/4 started at 950.0328 s\n",
      "train loss: 0.0245 acc: 0.9941 auc: 0.9478\n",
      "\n",
      "training completed in 21 m 36.2425 s\n",
      "best training auc: 0.9478\n"
     ]
    }
   ],
   "source": [
    "trained_cnn_end, save_folder_cnn_end = make_trained_model(hyp_cnn_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8 m 14 s] peptide dataset initialized\n"
     ]
    }
   ],
   "source": [
    "dataset = impepdom.PeptideDataset(\n",
    "    hla_allele='HLA-A01:01',\n",
    "    padding='end',\n",
    "    toy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
       " array([0., 0., 0., ..., 0., 0., 0.]))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.get_fold()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. Impepdom CNN, Padding End (B08:01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hla_allele': 'HLA-B08:01',\n",
       " 'padding': 'end',\n",
       " 'batch_size': 32,\n",
       " 'num_epochs': 9,\n",
       " 'learning_rate': 0.001,\n",
       " 'min_auc': [0.9529939536379968, 0.961533306486236, 0.9580878946911502],\n",
       " 'mean_ppv': [0.7607938897458618, 0.7426148757544642, 0.7399735726818328],\n",
       " 'mean_pcc': [0.7852789903522068, 0.7810577608677632, 0.773902509671378],\n",
       " 'dropout_input': 0.31666666666666665,\n",
       " 'dropout_hidden': 0.6166666666666667,\n",
       " 'conv': False,\n",
       " 'num_conv_layers': 2,\n",
       " 'conv_filt_sz': 5,\n",
       " 'conv_stride': 1}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyp_cnn_end_b0801 = get_best_hyperparams('mlp_2x100_cnn_b08:01.csv', padding='end')\n",
    "hyp_cnn_end_b0801"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_cnn_end_b0801, save_folder_cnn_end_b0801 = make_trained_model(hyp_cnn_end_b0801)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.5 64-bit ('mhc-1-immunopeptidome-characterization': pipenv)",
   "language": "python",
   "name": "python36564bitmhc1immunopeptidomecharacterizationpipenvfc41a3270a904987954d451e24bbfe16"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

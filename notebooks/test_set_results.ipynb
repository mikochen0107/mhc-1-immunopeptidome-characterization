{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impepdom Test Set Performance Analyses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")  # add top folder to path\n",
    "from collections import Counter\n",
    "import random\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as sts\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "import impepdom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Should make this whole block as functions inside Impepdom package later\n",
    "'''\n",
    "def weighted_harmonic_mean(var_1, var_2, beta=1):  # should make it generalizable to many variables\n",
    "    '''\n",
    "    Harmonic mean for two parameters with weighting.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    var_1, var_2: int or ndarray\n",
    "        Variables to consider\n",
    "        \n",
    "    beta: float, optional\n",
    "        Importance of `var_2` relative to `var_1`.\n",
    "        If beta == 1, this function is equivalent to `scipy.stats.hmean()`\n",
    "    '''\n",
    "    \n",
    "    return (1 + beta**2) * np.multiply(var_1, var_2) / (beta**2 * var_1 + var_2)\n",
    "\n",
    "def get_best_hyperparams(file, padding='end'):\n",
    "    '''\n",
    "    Extract the best hyperparameters for a model with harmonic weighting\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file: string\n",
    "        Name of the CSV file contraining hyperparam results\n",
    "    '''\n",
    "\n",
    "    path = '../store/hyperparams'\n",
    "\n",
    "    file_end = file.find('.csv')\n",
    "    file_begin = max(file.find('mlp'), file.find('cnn'))\n",
    "    all_name = file[file_end-6:file_end-2] + (':' if file.find(':') == -1 else '') + file[file_end-2:file_end]\n",
    "    allele = 'HLA-' + all_name.upper() # change to appropriate name\n",
    "\n",
    "    df = pd.read_csv(path + '/' + file)\n",
    "    correct_padding = (df['padding'] == padding)\n",
    "    df = df[correct_padding].reset_index()\n",
    "    idx = (df['min_auc'].notna() & df['mean_ppv'].notna())\n",
    "    \n",
    "    metric_1, metric_2 = np.array(df['min_auc'][idx]), np.array(df['mean_ppv'][idx])\n",
    "    beta = 1  # how much the second metric should be weighted compared to the first\n",
    "    w_hmean = weighted_harmonic_mean(metric_1, metric_2, beta=0.6)\n",
    "    \n",
    "    best_3_rows = (-w_hmean).argsort()[:3] # for top 3 rows with best harmonic mean value\n",
    "    # best_3_rows = (-sts.hmean([df['min_auc'][idx], df['mean_ppv'][idx]])).argsort()[:3]\n",
    "    \n",
    "    batch_sizes = list(df['batch_size'][best_3_rows].astype('int'))\n",
    "    batch_counter = Counter(batch_sizes)\n",
    "    batch_sz = batch_counter.most_common(1)[0][0]\n",
    "    \n",
    "    hyperparams = {\n",
    "        'hla_allele': allele, \n",
    "        'padding': padding,\n",
    "        'batch_size': batch_sz, \n",
    "        'num_epochs': int(np.mean(df['num_epochs'][best_3_rows])),\n",
    "        'learning_rate': float(np.mean(df['learning_rate'][best_3_rows])),\n",
    "\n",
    "        'min_auc': list(metric_1[best_3_rows]),\n",
    "        'mean_ppv': list(metric_2[best_3_rows]),\n",
    "    }\n",
    "\n",
    "    if 'mean_pcc' in df.columns:\n",
    "        hyperparams['mean_pcc'] = list(df['mean_pcc'][best_3_rows])\n",
    "    if 'dropout_input' in df.columns and 'dropout_hidden' in df.columns:\n",
    "        hyperparams['dropout_input'] = float(np.mean(df['dropout_input'][best_3_rows]))\n",
    "        hyperparams['dropout_hidden'] = float(np.mean(df['dropout_hidden'][best_3_rows]))\n",
    "    else:\n",
    "        hyperparams['dropout_input'] = 0.65  # stolen from MLP end\n",
    "        hyperparams['dropout_hidden'] = 0.46\n",
    "        \n",
    "    hyperparams['conv'] = False\n",
    "    if 'conv' in df.columns:\n",
    "        if df['conv'][0] == 'True':\n",
    "            hyperparams['conv'] = True\n",
    "            \n",
    "    if 'num_conv_layers' in df.columns and 'conv_filt_sz' in df.columns\tand 'conv_stride' in df.columns:\n",
    "        hyperparams['num_conv_layers'] = int(np.max(df['num_conv_layers'][best_3_rows]))\n",
    "        hyperparams['conv_filt_sz'] = int(np.max(df['conv_filt_sz'][best_3_rows]))\n",
    "        hyperparams['conv_stride'] = int(np.max(df['conv_stride'][best_3_rows]))\n",
    "    else:\n",
    "        hyperparams['num_conv_layers'] = 1  # default params for conv\n",
    "        hyperparams['conv_filt_sz'] = 5\n",
    "        hyperparams['conv_stride'] = 2\n",
    "\n",
    "    return hyperparams\n",
    "\n",
    "def make_trained_model(hyperparams):\n",
    "    results = []\n",
    "\n",
    "    impepdom.time_tracker.reset_timer() \n",
    "\n",
    "    print('working with allele', hyperparams['hla_allele'])\n",
    "    dataset = impepdom.PeptideDataset(\n",
    "        hla_allele=hyperparams['hla_allele'],\n",
    "        padding=hyperparams['padding'],\n",
    "        toy=False)\n",
    "\n",
    "    save_folder, baseline_metrics, _ = impepdom.run_experiment(\n",
    "        model_type='MultilayerPerceptron',  # passing model type here\n",
    "        dataset=dataset,\n",
    "        train_fold_idx=[0, 1, 2, 3, 4],\n",
    "        learning_rate=hyperparams['learning_rate'],\n",
    "        num_epochs=hyperparams['num_epochs'],\n",
    "        batch_size=hyperparams['batch_size'],\n",
    "\n",
    "        show_output=True,\n",
    "        dropout_input=hyperparams['dropout_input'],\n",
    "        dropout_hidden=hyperparams['dropout_hidden'],\n",
    "\n",
    "        conv=hyperparams['conv'],\n",
    "        num_conv_layers=hyperparams['num_conv_layers'],\n",
    "        conv_filt_sz=hyperparams['conv_filt_sz'],\n",
    "        conv_stride=hyperparams['conv_stride']\n",
    "    )\n",
    "\n",
    "    model = impepdom.models['MultilayerPerceptron'](\n",
    "        dropout_input=hyperparams['dropout_input'],\n",
    "        dropout_hidden=hyperparams['dropout_hidden'],\n",
    "\n",
    "        conv=hyperparams['conv'],\n",
    "        num_conv_layers=hyperparams['num_conv_layers'],\n",
    "        conv_filt_sz=hyperparams['conv_filt_sz'],\n",
    "        conv_stride=hyperparams['conv_stride']\n",
    "    )\n",
    "    \n",
    "    # to load a trained model, you would need to initialize the model outside\n",
    "    # smth like (untrained) `model = impepdom.models.MultilayerPerceptron(num_hidden_layers=2, hidden_layer_size=100)`\n",
    "    # but specify params exactly the same as in hyperparam_search\n",
    "                                                                    # get from csv file (column \"model\")\n",
    "    trained_model, _ = impepdom.load_trained_model(model, save_folder)\n",
    "\n",
    "    return trained_model, save_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_AA = ['A', 'R', 'N', 'D', 'C', 'E', 'Q', 'G', 'H', 'I', 'L', 'K', 'M', 'F', 'P', 'S', 'T', 'W', 'Y', 'V', 'U', 'X']\n",
    "NUM_AA = len(ALL_AA)  # number of amino acids (21 + 1 unknown)\n",
    "\n",
    "def load_epitopes_data(allele):\n",
    "    cd8_epitopes = '../datasets/test_sets/epitopes/processed'\n",
    "    \n",
    "    allele_epitopes = []\n",
    "    for epitope in os.listdir(cd8_epitopes):\n",
    "        if epitope.find(allele) >= 0:\n",
    "            allele_epitopes.append(epitope)\n",
    "    \n",
    "    epitopes_data = {}\n",
    "    for epi in allele_epitopes:\n",
    "        key = epi[epi.find('_') + 1:epi.find('.txt')]\n",
    "        epitopes_data[key] = (pd.read_csv(os.path.join(cd8_epitopes, epi), header=None, names=['peptide', 'label'], delimiter=' '))\n",
    "                             \n",
    "    return epitopes_data\n",
    "\n",
    "def pad(seq, padding):\n",
    "    pad_len = 14 * NUM_AA - len(seq)  # number of bits to pad\n",
    "    pad_bits = '0' * pad_len\n",
    "\n",
    "    if padding == 'end':\n",
    "        padded_seq = seq + pad_bits\n",
    "    elif padding == 'flurry':\n",
    "        pep_len = len(seq) // NUM_AA\n",
    "        if pep_len < 9:  # pad after 3rd bit\n",
    "            pos = 4 * NUM_AA\n",
    "        elif pep_len == 9:\n",
    "            pos = (4 if random.random() < 0.5 else 5) * NUM_AA\n",
    "        else:\n",
    "            pos = 5 * NUM_AA\n",
    "        padded_seq = seq[:pos] + pad_bits + seq[pos:]\n",
    "\n",
    "    return padded_seq\n",
    "\n",
    "def encoded_epitopes(_epitopes_data, padding='end'):\n",
    "    epitopes_data = copy.deepcopy(_epitopes_data)\n",
    "    for _, epi in epitopes_data.items():\n",
    "        for i in range(epi.shape[0]):\n",
    "            seq = epi['peptide'][i]\n",
    "            bin_seq = '' \n",
    "            \n",
    "            for aa in seq:\n",
    "                if aa == '0':\n",
    "                    print(epi)\n",
    "                bin_placeholder = '0' * NUM_AA\n",
    "                insert_pos = ALL_AA.index(aa)\n",
    "                bin_aa = bin_placeholder[:insert_pos] + '1' + bin_placeholder[insert_pos+1:]\n",
    "                bin_seq += bin_aa\n",
    "                \n",
    "            epi['peptide'][i] = pad(bin_seq, padding=padding)\n",
    "            \n",
    "    return epitopes_data\n",
    "\n",
    "def get_data_and_targets(encoded_epitopes):\n",
    "    data_store = {}\n",
    "    targets_store = {}\n",
    "    \n",
    "    for key, epi in encoded_epitopes.items():\n",
    "        data = np.vstack([np.array(list(pep), dtype=float) for pep in epi['peptide']])\n",
    "        data_store[key] = data\n",
    "        targets_store[key] = np.array(epi['label'], dtype=float)\n",
    "        \n",
    "    return data_store, targets_store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model, X_test_store):\n",
    "    y_pred_store = {}\n",
    "    for key, X_test in X_test_store.items():\n",
    "        y_pred_store[key] = predict(model, X_test)\n",
    "        \n",
    "    return y_pred_store\n",
    "\n",
    "def predict(model, X_test):\n",
    "    y_proba = model(torch.tensor(X_test, dtype=torch.float)).detach().numpy().reshape(-1)\n",
    "    \n",
    "    return y_proba\n",
    "\n",
    "def f_rank(y_true, y_proba):\n",
    "    sorted_y_true = np.flip([x for _, x in sorted(zip(y_proba, y_true))])\n",
    "    rank = np.where(sorted_y_true == 1)[0][0]\n",
    "    f_rank = rank / sorted_y_true.size\n",
    "    \n",
    "    return f_rank\n",
    "\n",
    "def get_metrics(y_test_store, y_pred_store):\n",
    "    scores_store = {}\n",
    "    \n",
    "    for key in y_pred_store.keys():\n",
    "        scores_store[key] = {\n",
    "            'auc': impepdom.metrics.auc(y_test_store[key], y_pred_store[key]),\n",
    "            'f_rank': f_rank(y_test_store[key], y_pred_store[key])\n",
    "        }\n",
    "        \n",
    "    return scores_store\n",
    "\n",
    "def get_table8(y_test_store, y_pred_store):\n",
    "    scores_store = {}\n",
    "    \n",
    "    for key in y_pred_store.keys():\n",
    "        scores_store['HLA-B08:01'] = {\n",
    "            'auc': impepdom.metrics.auc(y_test_store[key], y_pred_store[key]),\n",
    "            'auc_01': impepdom.metrics.auc_01(y_test_store[key], y_pred_store[key]),\n",
    "            'ppv': impepdom.metrics.ppv(y_test_store[key], y_pred_store[key])\n",
    "        }\n",
    "        \n",
    "    return scores_store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_report(scores_store, filename):\n",
    "    pep_col = []\n",
    "    auc_col = []\n",
    "    frank_col = []\n",
    "    \n",
    "    for key, scores in scores_store.items():\n",
    "        pep_col.append(key)\n",
    "        auc_col.append(scores['auc'])\n",
    "        frank_col.append(scores['f_rank'])\n",
    "        \n",
    "    report = pd.DataFrame({'Epitope': pep_col, 'AUC': auc_col, 'FRANK': frank_col})\n",
    "    \n",
    "    report_root = '../store/reports/presentation'\n",
    "    report.to_csv(os.path.join(report_root, filename))\n",
    "    \n",
    "    return report\n",
    "\n",
    "def generate_table8(scores_store, filename):\n",
    "    mhc_col = []\n",
    "    auc_col = []\n",
    "    auc_01_col = []\n",
    "    ppv_col = []\n",
    "    \n",
    "    for key, scores in scores_store.items():\n",
    "        mhc_col.append(key)\n",
    "        auc_col.append(scores['auc'])\n",
    "        auc_01_col.append(scores['auc_01'])\n",
    "        ppv_col.append(scores['ppv'])\n",
    "        \n",
    "    report = pd.DataFrame({'MHC': mhc_col, 'AUC': auc_col, 'AUC0.1': auc_01_col, 'PPV': ppv_col})\n",
    "    \n",
    "    report_root = '../store/reports/presentation'\n",
    "    report.to_csv(os.path.join(report_root, filename))\n",
    "    \n",
    "    return report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Impepdom MLP, Padding End (A01:01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hla_allele': 'HLA-A01:01',\n",
       " 'padding': 'end',\n",
       " 'batch_size': 32,\n",
       " 'num_epochs': 10,\n",
       " 'learning_rate': 0.001,\n",
       " 'min_auc': [0.8977589504924592, 0.8961656106026613, 0.8990260131998715],\n",
       " 'mean_ppv': [0.5537177398133175, 0.5552848410310801, 0.5488537884133244],\n",
       " 'mean_pcc': [0.6042904818034925, 0.6009710200191343, 0.6021092651503497],\n",
       " 'dropout_input': 0.65,\n",
       " 'dropout_hidden': 0.4666666666666666,\n",
       " 'conv': False,\n",
       " 'num_conv_layers': 2,\n",
       " 'conv_filt_sz': 5,\n",
       " 'conv_stride': 1}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyp_mlp_end = get_best_hyperparams('mlp_2x100_a01:01.csv', padding='end')\n",
    "hyp_mlp_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working with allele HLA-A01:01\n",
      "[1 m 12 s] peptide dataset initialized\n",
      "epoch 1/10 started at 0.0005 s\n",
      "train loss: 0.0366 acc: 0.9917 auc: 0.8827\n",
      "\n",
      "epoch 2/10 started at 76.0032 s\n",
      "train loss: 0.0339 acc: 0.9926 auc: 0.8911\n",
      "\n",
      "epoch 3/10 started at 149.1546 s\n",
      "train loss: 0.0329 acc: 0.9928 auc: 0.8922\n",
      "\n",
      "epoch 4/10 started at 221.5307 s\n",
      "train loss: 0.0313 acc: 0.9932 auc: 0.8967\n",
      "\n",
      "epoch 5/10 started at 294.6287 s\n",
      "train loss: 0.0321 acc: 0.9932 auc: 0.8904\n",
      "\n",
      "epoch 6/10 started at 368.3679 s\n",
      "train loss: 0.0313 acc: 0.9933 auc: 0.8961\n",
      "\n",
      "epoch 7/10 started at 443.1616 s\n",
      "train loss: 0.0325 acc: 0.9930 auc: 0.8905\n",
      "\n",
      "epoch 8/10 started at 518.5411 s\n",
      "train loss: 0.0312 acc: 0.9932 auc: 0.8932\n",
      "\n",
      "epoch 9/10 started at 594.3561 s\n",
      "train loss: 0.0314 acc: 0.9932 auc: 0.8917\n",
      "\n",
      "epoch 10/10 started at 670.5593 s\n",
      "train loss: 0.0317 acc: 0.9932 auc: 0.8860\n",
      "\n",
      "training completed in 12 m 35.4826 s\n",
      "best training auc: 0.8967\n"
     ]
    }
   ],
   "source": [
    "trained_mlp_end, save_folder_mlp_end = make_trained_model(hyp_mlp_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Munchic/.local/share/virtualenvs/mhc-1-immunopeptidome-characterization-yRC4iDIz/lib/python3.6/site-packages/ipykernel_launcher.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "hla_a0101_epitopes_data = load_epitopes_data('HLA-A01:01')\n",
    "data_end = encoded_epitopes(hla_a0101_epitopes_data, padding='end')\n",
    "X_test_store_end, y_test_store_end = get_data_and_targets(data_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_store_end = get_predictions(trained_mlp_end, X_test_store_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_mlp_end = get_metrics(y_test_store_end, y_pred_store_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_mlp_end_df = generate_report(scores_mlp_end, 'mlp_2x10_a01:01_end.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Impepdom MLP, Padding Flurry (A01:01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hla_allele': 'HLA-A01:01',\n",
       " 'padding': 'flurry',\n",
       " 'batch_size': 32,\n",
       " 'num_epochs': 2,\n",
       " 'learning_rate': 0.005,\n",
       " 'min_auc': [0.872914348179539, 0.8887562782268924, 0.8829656080326539],\n",
       " 'mean_ppv': [0.702036238962418, 0.6725481692381067, 0.6724674239309099],\n",
       " 'dropout_input': 0.65,\n",
       " 'dropout_hidden': 0.46,\n",
       " 'conv': False,\n",
       " 'num_conv_layers': 1,\n",
       " 'conv_filt_sz': 5,\n",
       " 'conv_stride': 2}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyp_mlp_flurry = get_best_hyperparams('flurry_mlp_2x100_a01:01.csv', padding='flurry')\n",
    "hyp_mlp_flurry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working with allele HLA-A01:01\n",
      "[1 m 18 s] peptide dataset initialized\n",
      "epoch 1/2 started at 0.0006 s\n",
      "train loss: 0.0367 acc: 0.9921 auc: 0.8990\n",
      "\n",
      "epoch 2/2 started at 80.6436 s\n",
      "train loss: 0.0360 acc: 0.9923 auc: 0.9101\n",
      "\n",
      "training completed in 2 m 38.5692 s\n",
      "best training auc: 0.9101\n"
     ]
    }
   ],
   "source": [
    "trained_mlp_flurry, save_folder_mlp_flurry = make_trained_model(hyp_mlp_flurry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Munchic/.local/share/virtualenvs/mhc-1-immunopeptidome-characterization-yRC4iDIz/lib/python3.6/site-packages/ipykernel_launcher.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# hla_a0101_epitopes_data = load_epitopes_data('HLA-A01:01')\n",
    "data_flurry = encoded_epitopes(hla_a0101_epitopes_data, padding='flurry')\n",
    "X_test_store_flurry, y_test_store_flurry = get_data_and_targets(data_flurry)\n",
    "y_pred_store_flurry = get_predictions(trained_mlp_flurry, X_test_store_flurry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_mlp_flurry = get_metrics(y_test_store_flurry, y_pred_store_flurry)\n",
    "scores_mlp_flurry_df = generate_report(scores_mlp_flurry, 'mlp_2x10_a01:01_flurry.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Impepdom CNN, Padding Flurry (A01:01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hla_allele': 'HLA-A01:01',\n",
       " 'padding': 'flurry',\n",
       " 'batch_size': 32,\n",
       " 'num_epochs': 6,\n",
       " 'learning_rate': 0.0007,\n",
       " 'min_auc': [0.9343186974226512, 0.930497976816677, 0.935205387103132],\n",
       " 'mean_ppv': [0.5999044863447609, 0.6009233348300029, 0.5940511290114937],\n",
       " 'mean_pcc': [0.6569269182965304, 0.6589301105293429, 0.6550037584822265],\n",
       " 'dropout_input': 0.16666666666666666,\n",
       " 'dropout_hidden': 0.4166666666666667,\n",
       " 'conv': True,\n",
       " 'num_conv_layers': 2,\n",
       " 'conv_filt_sz': 5,\n",
       " 'conv_stride': 1}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyp_cnn_flurry = get_best_hyperparams('mlp_2x100_cnn_a01:01.csv', padding='flurry')\n",
    "hyp_cnn_flurry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working with allele HLA-A01:01\n",
      "[1 m 16 s] peptide dataset initialized\n",
      "epoch 1/6 started at 0.0008 s\n",
      "train loss: 0.0303 acc: 0.9930 auc: 0.9142\n",
      "\n",
      "epoch 2/6 started at 295.2853 s\n",
      "train loss: 0.0265 acc: 0.9937 auc: 0.9341\n",
      "\n",
      "epoch 3/6 started at 600.7621 s\n",
      "train loss: 0.0257 acc: 0.9938 auc: 0.9426\n",
      "\n",
      "epoch 4/6 started at 995.9847 s\n",
      "train loss: 0.0248 acc: 0.9941 auc: 0.9441\n",
      "\n",
      "epoch 5/6 started at 1340.9808 s\n",
      "train loss: 0.0250 acc: 0.9939 auc: 0.9463\n",
      "\n",
      "epoch 6/6 started at 1683.5154 s\n",
      "train loss: 0.0241 acc: 0.9942 auc: 0.9516\n",
      "\n",
      "training completed in 33 m 45.9678 s\n",
      "best training auc: 0.9516\n"
     ]
    }
   ],
   "source": [
    "trained_cnn_flurry, save_folder_cnn_flurry = make_trained_model(hyp_cnn_flurry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_store_cnn_flurry = get_predictions(trained_cnn_flurry, X_test_store_flurry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_cnn_flurry = get_metrics(y_test_store_flurry, y_pred_store_cnn_flurry)\n",
    "scores_cnn_flurry_df = generate_report(scores_cnn_flurry, 'cnn_mlp_2x10_a01:01_flurry.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Impepdom CNN, Padding End (A01:01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hla_allele': 'HLA-A01:01',\n",
       " 'padding': 'end',\n",
       " 'batch_size': 32,\n",
       " 'num_epochs': 4,\n",
       " 'learning_rate': 0.0007,\n",
       " 'min_auc': [0.9368633953874179, 0.9313492851709656, 0.9336545279088934],\n",
       " 'mean_ppv': [0.5958793626912142, 0.597742716862056, 0.5931293774163101],\n",
       " 'mean_pcc': [0.6562752247286305, 0.6550852579461708, 0.6530620180032013],\n",
       " 'dropout_input': 0.18333333333333335,\n",
       " 'dropout_hidden': 0.45,\n",
       " 'conv': True,\n",
       " 'num_conv_layers': 2,\n",
       " 'conv_filt_sz': 5,\n",
       " 'conv_stride': 1}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyp_cnn_end = get_best_hyperparams('mlp_2x100_cnn_a01:01.csv', padding='end')\n",
    "hyp_cnn_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working with allele HLA-A01:01\n",
      "[1 m 15 s] peptide dataset initialized\n",
      "epoch 1/4 started at 0.0006 s\n",
      "train loss: 0.0317 acc: 0.9929 auc: 0.9056\n",
      "\n",
      "epoch 2/4 started at 308.7786 s\n",
      "train loss: 0.0260 acc: 0.9939 auc: 0.9386\n",
      "\n",
      "epoch 3/4 started at 627.1995 s\n",
      "train loss: 0.0254 acc: 0.9938 auc: 0.9438\n",
      "\n",
      "epoch 4/4 started at 950.0328 s\n",
      "train loss: 0.0245 acc: 0.9941 auc: 0.9478\n",
      "\n",
      "training completed in 21 m 36.2425 s\n",
      "best training auc: 0.9478\n"
     ]
    }
   ],
   "source": [
    "trained_cnn_end, save_folder_cnn_end = make_trained_model(hyp_cnn_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_store_cnn_end = get_predictions(trained_cnn_end, X_test_store_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_cnn_end = get_metrics(y_test_store_end, y_pred_store_cnn_end)\n",
    "scores_cnn_end_df = generate_report(scores_cnn_end, 'cnn_mlp_2x10_a01:01_end.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. Impepdom CNN, Padding End (B08:01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hla_allele': 'HLA-B08:01',\n",
       " 'padding': 'end',\n",
       " 'batch_size': 32,\n",
       " 'num_epochs': 9,\n",
       " 'learning_rate': 0.001,\n",
       " 'min_auc': [0.9529939536379968, 0.961533306486236, 0.9580878946911502],\n",
       " 'mean_ppv': [0.7607938897458618, 0.7426148757544642, 0.7399735726818328],\n",
       " 'mean_pcc': [0.7852789903522068, 0.7810577608677632, 0.773902509671378],\n",
       " 'dropout_input': 0.31666666666666665,\n",
       " 'dropout_hidden': 0.6166666666666667,\n",
       " 'conv': False,\n",
       " 'num_conv_layers': 2,\n",
       " 'conv_filt_sz': 5,\n",
       " 'conv_stride': 1}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyp_cnn_end_b0801 = get_best_hyperparams('mlp_2x100_cnn_b08:01.csv', padding='end')\n",
    "hyp_cnn_end_b0801"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working with allele HLA-B08:01\n",
      "[0 m 15 s] peptide dataset initialized\n",
      "epoch 1/9 started at 0.0004 s\n",
      "train loss: 0.0521 acc: 0.9867 auc: 0.9350\n",
      "\n",
      "epoch 2/9 started at 15.8460 s\n",
      "train loss: 0.0401 acc: 0.9898 auc: 0.9520\n",
      "\n",
      "epoch 3/9 started at 31.7083 s\n",
      "train loss: 0.0391 acc: 0.9904 auc: 0.9526\n",
      "\n",
      "epoch 4/9 started at 47.4721 s\n",
      "train loss: 0.0366 acc: 0.9913 auc: 0.9568\n",
      "\n",
      "epoch 5/9 started at 63.4131 s\n",
      "train loss: 0.0364 acc: 0.9913 auc: 0.9563\n",
      "\n",
      "epoch 6/9 started at 79.4136 s\n",
      "train loss: 0.0364 acc: 0.9913 auc: 0.9582\n",
      "\n",
      "epoch 7/9 started at 95.3860 s\n",
      "train loss: 0.0341 acc: 0.9918 auc: 0.9605\n",
      "\n",
      "epoch 8/9 started at 111.3404 s\n",
      "train loss: 0.0323 acc: 0.9923 auc: 0.9639\n",
      "\n",
      "epoch 9/9 started at 127.2869 s\n",
      "train loss: 0.0307 acc: 0.9930 auc: 0.9626\n",
      "\n",
      "training completed in 2 m 23.3785 s\n",
      "best training auc: 0.9639\n"
     ]
    }
   ],
   "source": [
    "trained_cnn_end_b0801, save_folder_cnn_end_b0801 = make_trained_model(hyp_cnn_end_b0801)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some trick here\n",
    "epitopes_data_b0801 = {}\n",
    "path_to_test = '../datasets/test_sets/MS_ligands/processed'\n",
    "epitopes_data_b0801['1'] = pd.read_csv(os.path.join(path_to_test, 'HLA-B08:01_test.txt'), header=None, names=['peptide', 'label'], delimiter=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Munchic/.local/share/virtualenvs/mhc-1-immunopeptidome-characterization-yRC4iDIz/lib/python3.6/site-packages/ipykernel_launcher.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "encoded_data_b0801 = encoded_epitopes(epitopes_data_b0801, padding='end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_store_end_b0801, y_test_store_end_b0801 = get_data_and_targets(encoded_data_b0801)\n",
    "y_pred_store_end_b0801 = get_predictions(trained_cnn_end_b0801, X_test_store_end_b0801)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_cnn_end_b0801 = get_table8(y_test_store_end_b0801, y_pred_store_end_b0801)\n",
    "scores_mlp_end_b0801_df = generate_table8(scores_cnn_end_b0801, 'cnn_2x10_b08:01_end.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MHC</th>\n",
       "      <th>AUC</th>\n",
       "      <th>AUC0.1</th>\n",
       "      <th>PPV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HLA-B08:01</td>\n",
       "      <td>0.929698</td>\n",
       "      <td>0.884152</td>\n",
       "      <td>0.705556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          MHC       AUC    AUC0.1       PPV\n",
       "0  HLA-B08:01  0.929698  0.884152  0.705556"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_mlp_end_b0801_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.5 64-bit ('mhc-1-immunopeptidome-characterization': pipenv)",
   "language": "python",
   "name": "python36564bitmhc1immunopeptidomecharacterizationpipenvfc41a3270a904987954d451e24bbfe16"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")  # add top folder to path\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as sts\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import impepdom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_harmonic_mean(var_1, var_2, beta=1):  # should make it generalizable to many variables\n",
    "    '''\n",
    "    Harmonic mean for two parameters with weighting.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    var_1, var_2: int or ndarray\n",
    "        Variables to consider\n",
    "        \n",
    "    beta: float, optional\n",
    "        Importance of `var_2` relative to `var_1`.\n",
    "        If beta == 1, this function is equivalent to `scipy.stats.hmean()`\n",
    "    '''\n",
    "    \n",
    "    return (1 + beta**2) * np.multiply(var_1, var_2) / (beta**2 * var_1 + var_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import csv and extract best hyperparameters\n",
    "\n",
    "path = '../store/hyperparams'\n",
    "\n",
    "hyperparams = []\n",
    "\n",
    "\n",
    "for file in ['/mlp_2x100_cnn_b08:01.csv']: # add '/mlp_2x100_cnn_a01/01.csv', \n",
    "    all_name = file[15:-4]\n",
    "    allele = 'HLA-' + all_name.upper() # change to appropriate name\n",
    "    df = pd.read_csv(path + file)\n",
    "    idx = (df['min_auc'].notna() & df['mean_pcc'].notna())\n",
    "    \n",
    "    metric_1, metric_2 = np.array(df['min_auc'][idx]), np.array(df['mean_pcc'][idx]) # change from ppv to pcc\n",
    "    beta = 1  # how much the second metric should be weighted compared to the first\n",
    "    w_hmean = weighted_harmonic_mean(metric_1, metric_2, beta=0.6)\n",
    "    \n",
    "    best_3_rows = (-w_hmean).argsort()[:3] # for top 3 rows with best harmonic mean value\n",
    "    \n",
    "    batch_sizes = list(df['batch_size'][best_3_rows].astype('int'))\n",
    "    batch_counter = Counter(batch_sizes)\n",
    "    batch_sz = batch_counter.most_common(1)[0][0]\n",
    "    \n",
    "    hyperparams.append({\n",
    "        'hla_allele': allele, \n",
    "        'padding': 'flurry',\n",
    "        'batch_size': batch_sz, \n",
    "        'num_epochs': int(np.mean(df['num_epochs'][best_3_rows])),\n",
    "        'learning_rate': float(np.mean(df['learning_rate'][best_3_rows])),\n",
    "        'dropout_input': float(np.mean(df['dropout_input'][best_3_rows])),\n",
    "        'dropout_hidden': float(np.mean(df['dropout_hidden'][best_3_rows])),\n",
    "        'min_auc': list(metric_1[best_3_rows]),\n",
    "        'mean_pcc': list(metric_2[best_3_rows])\n",
    "    })\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'hla_allele': 'HLA-B08:01',\n",
       "  'padding': 'flurry',\n",
       "  'batch_size': 32,\n",
       "  'num_epochs': 8,\n",
       "  'learning_rate': 0.001,\n",
       "  'dropout_input': 0.3333333333333333,\n",
       "  'dropout_hidden': 0.6666666666666666,\n",
       "  'min_auc': [0.961533306486236, 0.9586539891169714, 0.9529939536379968],\n",
       "  'mean_pcc': [0.7810577608677632, 0.7834574843780465, 0.7852789903522068]}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working with allele HLA-B08:01\n",
      "[0 m 23 s] peptide dataset initialized\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'cnn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-2079a5147bcd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhyp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'learning_rate'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhyp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhyp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     )\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/unsam/impepdom/experiment_runner.py\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(model_type, dataset, train_fold_idx, val_fold_idx, criterion, optimizer, scheduler, batch_size, num_epochs, learning_rate, show_output, dropout_input, dropout_hidden, conv, num_conv_layers, conv_filt_sz, conv_stride, model_run_time)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;31m# (re-)initialize model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     model = impepdom.models[model_type](\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0mhidden_layer_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'cnn'"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "impepdom.time_tracker.reset_timer() \n",
    "\n",
    "for hyp in hyperparams:\n",
    "    print('working with allele', hyp['hla_allele'])\n",
    "    model = impepdom.MultilayerPerceptron(num_hidden_layers=2, hidden_layer_size=100, dropout_input=hyp['dropout_input'], \n",
    "                                                 dropout_hidden=hyp['dropout_hidden'], conv=True, num_conv_layers=2, conv_filt_sz=5, conv_stride=1)\n",
    "    \n",
    "    dataset = impepdom.PeptideDataset(\n",
    "        hla_allele=hyp['hla_allele'],\n",
    "        padding='end',\n",
    "        toy=False)\n",
    "\n",
    "    save_folder, baseline_metrics, _ = impepdom.run_experiment(\n",
    "        model_type='cnn',\n",
    "        dataset=dataset,\n",
    "        train_fold_idx=[0, 1, 2, 3],\n",
    "        learning_rate=hyp['learning_rate'],\n",
    "        num_epochs=hyp['num_epochs'],\n",
    "        batch_size=hyp['batch_size'],\n",
    "    )\n",
    "    \n",
    "    trained_model, train_history = impepdom.load_trained_model(model, save_folder)\n",
    "    \n",
    "    \n",
    "    X_test, y_test = dataset.get_fold(fold_idx=[4])\n",
    "    y_proba = model(torch.tensor(X_test, dtype=torch.float)).detach().numpy()\n",
    "    \n",
    "    results.append({\n",
    "        'hla_allele': hyp['hla_allele'],\n",
    "        'y_test': y_test,\n",
    "        'y_proba': y_proba\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Allele A01:01 test set eval - calculating the F ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Allele B08:01 test set eval - calculating the AUC, PPC\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
